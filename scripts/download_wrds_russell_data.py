"""Download Russell 3000 constituent data from WRDS.

This helper queries the CRSP daily stock file for every permno listed in the
normalized Russell 3000 constituent CSVs.  It pivots the long-format results
into the wide layout expected by the portfolio construction pipeline and also
computes an equal-weight benchmark return series that can be used as a proxy for
the index if no official Russell 3000 total-return series is available.

Example
-------
Activate the project's virtual environment, then run::

    python scripts/download_wrds_russell_data.py \
        --permno-csv financial_data/russel3000/constituants/all_permnos.csv \
        --start-date 2014-01-01 \
        --end-date 2023-12-31

Install the ``wrds`` and ``psycopg2-binary`` packages in the virtual
environment beforehand with ``pip install wrds psycopg2-binary``.
"""
from __future__ import annotations

import argparse
import math
from pathlib import Path
from typing import Iterable, List, Sequence

import pandas as pd

try:
    import wrds
except ImportError as exc:  # pragma: no cover - guidance script
    raise SystemExit(
        "The 'wrds' package is required. Install it with 'pip install wrds psycopg2-binary'."
    ) from exc

from psycopg2 import OperationalError as PsycopgOperationalError
from sqlalchemy.exc import OperationalError as SAOperationalError


def _chunked(sequence: Sequence[int], chunk_size: int) -> Iterable[List[int]]:
    """Yield ``chunk_size``-sized chunks from ``sequence``."""

    if chunk_size <= 0:
        raise ValueError("chunk_size must be positive")

    for start in range(0, len(sequence), chunk_size):
        yield list(sequence[start : start + chunk_size])


def _load_permnos(path: Path) -> List[int]:
    df = pd.read_csv(path, dtype={"permno": "string"})
    if "permno" not in df.columns:
        raise ValueError(f"Expected a 'permno' column in {path}")

    permnos = df["permno"].dropna().astype(str).str.strip()
    permnos = permnos[permnos != ""]
    unique_permnos = sorted({int(value) for value in permnos})
    if not unique_permnos:
        raise ValueError(f"No permnos found in {path}")
    return unique_permnos


def _fetch_crsp_returns(
    conn: "wrds.Connection",
    permnos: Sequence[int],
    start_date: str,
    end_date: str,
    chunk_size: int,
) -> pd.DataFrame:
    """Fetch daily returns for ``permnos`` from CRSP.DSF."""

    frames: list[pd.DataFrame] = []
    for idx, chunk in enumerate(_chunked(permnos, chunk_size), start=1):
        permno_sql = ",".join(str(number) for number in chunk)
        query = f"""
            select permno, date, ret
            from crsp.dsf
            where permno in ({permno_sql})
              and date between '{start_date}' and '{end_date}'
        """
        print(f"Downloading chunk {idx} / {math.ceil(len(permnos) / chunk_size)} (size={len(chunk)})...")
        frame = conn.raw_sql(query, date_cols=["date"])
        frames.append(frame)

    if not frames:
        raise RuntimeError("No data returned from CRSP.DSF")

    data = pd.concat(frames, ignore_index=True)
    data = data.dropna(subset=["date"])  # defensive
    data["permno"] = data["permno"].astype(int)
    data = data.sort_values(["date", "permno"]).drop_duplicates(subset=["date", "permno"], keep="last")
    return data


def _pivot_returns(data: pd.DataFrame) -> pd.DataFrame:
    wide = data.pivot(index="date", columns="permno", values="ret").sort_index()
    wide.columns = [str(col) for col in wide.columns]
    wide.index = pd.to_datetime(wide.index)
    wide.index.name = "date"
    return wide


def _compute_equal_weight_index(wide: pd.DataFrame) -> pd.DataFrame:
    index_returns = wide.mean(axis=1, skipna=True).to_frame(name="russell3000_equal_weight")
    index_returns.index.name = "Date"
    index_returns = index_returns.reset_index()
    index_returns["Date"] = index_returns["Date"].dt.strftime("%Y-%m-%d")
    return index_returns


def _write_returns(wide: pd.DataFrame, destination: Path) -> None:
    destination.parent.mkdir(parents=True, exist_ok=True)
    output = wide.reset_index()
    output["date"] = output["date"].dt.strftime("%Y-%m-%d")
    output.to_csv(destination, index=False)
    print(f"Wrote stock return matrix to {destination}")


def _write_index(index_df: pd.DataFrame, destination: Path) -> None:
    destination.parent.mkdir(parents=True, exist_ok=True)
    index_df.to_csv(destination, index=False)
    print(f"Wrote index proxy returns to {destination}")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Download Russell 3000 data from WRDS")
    parser.add_argument(
        "--permno-csv",
        type=Path,
        default=Path("financial_data/russel3000/constituants/all_permnos.csv"),
        help="Path to the CSV generated by prepare_russell_constituents.py",
    )
    parser.add_argument("--start-date", type=str, required=True, help="Start date (YYYY-MM-DD)")
    parser.add_argument("--end-date", type=str, required=True, help="End date (YYYY-MM-DD)")
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=200,
        help="Number of permnos to request per SQL query (default: %(default)s)",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("financial_data/russel3000"),
        help="Destination folder for the generated CSV files",
    )
    parser.add_argument(
        "--skip-index",
        action="store_true",
        help="Do not compute the equal-weight index proxy",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    permnos = _load_permnos(args.permno_csv)
    print(f"Loaded {len(permnos)} unique permnos from {args.permno_csv}")

    print("Connecting to WRDS (you will be prompted for credentials)...")
    try:
        conn = wrds.Connection()
    except (PsycopgOperationalError, SAOperationalError) as exc:
        raise SystemExit(
            "Failed to authenticate with WRDS.\n"
            "Please verify your username/password, ensure any required VPN is active, "
            "and confirm that your WRDS account is provisioned for PostgreSQL access.\n"
            f"Original error: {exc}"
        ) from exc
    except Exception as exc:  # pragma: no cover - defensive
        raise SystemExit("Unexpected error while connecting to WRDS: " + str(exc)) from exc

    try:
        returns_long = _fetch_crsp_returns(
            conn=conn,
            permnos=permnos,
            start_date=args.start_date,
            end_date=args.end_date,
            chunk_size=args.chunk_size,
        )
    finally:
        conn.close()

    returns_wide = _pivot_returns(returns_long)
    _write_returns(returns_wide, args.output_dir / "returns_stocks.csv")

    if not args.skip_index:
        index_df = _compute_equal_weight_index(returns_wide)
        _write_index(index_df, args.output_dir / "returns_index.csv")
    else:
        print("Skipping index proxy computation (per --skip-index)")


if __name__ == "__main__":
    main()
